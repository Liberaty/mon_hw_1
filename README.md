# Домашнее задание к занятию 13 «Введение в мониторинг»

## Обязательные задания
#
1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя платформу для вычислений с выдачей текстовых отчётов, которые сохраняются на диск. Взаимодействие с платформой осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы выведите в мониторинг и почему?
#
***Ответ***
#
	1. **HTTP-метрики** :
    - Количество запросов (всех типов — 2xx, 3xx, 4xx, 5xx).
    - Время ответа сервера.
    - Размер передаваемых данных (запросы/ответы) 
    
    Данные показатели позволят оценить производительность системы с точки зрения клиентов

	2. **CPU загрузка** :
    
    - Средняя загрузка CPU за последние 1, 5 и 15 минут (`load average`).
    - Использование CPU (%) по процессам или общее использование.

    Вычисления сильно нагружают CPU, поэтому его мониторинг особенно критичен для понимания производительности.
  
	3. **Дисковые метрики** :
    
    - Использованное пространство на диске.
    - Скорость записи/чтения файлов.
    - Количество свободных inode'ов.
    
    Текстовые отчеты сохраняются на диск, поэтому важно отслеживать доступность места и производительность диска.

	4. **RAM использование** :
    
    - Общий объем RAM.
    - Использованный объем RAM.
    - Доступная память.
    
    Нехватка оперативной памяти может привести к ошибкам, снижению производительности или падению сервиса.
#
2. Менеджер продукта, посмотрев на ваши метрики, сказал, что ему непонятно, что такое RAM/inodes/CPUla. Также он сказал, что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы можете ему предложить?
#
***Ответ***
#
	1. **SLA по времени ответа** :
    - Процент запросов, которые обрабатываются быстрее определенного порога (например, менее 1 секунды).
	2. **Процент успешных запросов** :
    - Отношение количества успешных запросов (2xx) ко всем запросам.
	3. **Количество клиентских запросов** :
    - Общее количество запросов за период времени.
	4. **Статистика отказов** :
    - Количество ошибок (если они есть) с детализацией по типам кодов ответа (например, 4xx/5xx).
	5. **График работы системы** :
    - Загрузка CPU, RAM и диска в реальном времени или за период времени.
	6. **Информация о времени простоя** :
    - Время, когда система не была доступна клиентам.
#    
3. Вашей DevOps-команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики, в свою очередь, хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, чтобы разработчики получали ошибки приложения?
#
***Ответ***
#
    Самым простым решением будет реализация точечного доступа к логам на боевых VM или контейнерах и будут сами за ними смотреть (доступ к конкретным логам и только на чтение)
#
4. Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA = 99% по http-кодам ответов. 
Этот параметр вычисляется по формуле: summ_2xx_requests/summ_all_requests. Он не поднимается выше 70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?
#
***Ответ***
#
    При расчетах не учтены коды 3хх вероятно на них приходиться 29% доли запросов пользователей
    Исправленная формула SLA = (summ_2xx_requests + summ_3xx_requests) / summ_all_requests
    также при расчетах не учтены и другие показатели которые прямо или косвенно влияют на общую картину.
#
5. Опишите основные плюсы и минусы pull и push систем мониторинга.
#
***Ответ***
#
    Push
    Плюсы:
    - Снижение нагрузки на сервисы — метрики отправляются только при доступности, а не на каждый цикл сбора.
    - Упрощение репликации данных в разные системы мониторинга или их резервные копии
    - более гибкая настройка отправки пакетов данных с метриками
    - Гибкость — подходит для коротких задач и сред, где источники не могут выставлять конечные точки для сбора метрик — сама задача инициирует отправку метрик.
    - Эффективность использования ресурсов — поскольку метрики отправляются только при доступности, этот метод может быть более эффективным с точки зрения использования сети и CPU.
#
    Минусы:
    - Риск потери метрик — если источник недоступен в момент, когда система мониторинга пытается собрать метрики, особенно в динамических средах.
    - Зависимость от внешних систем — для коротких задач или пакетных процессов зависимость от внешних систем (например, Pushgateway) может быть проблемой, так как они могут выйти из строя или стать единой точкой отказа
#
    Pull
    Плюсы:
    - Можно настроить единый proxy server до всех агентов с TLS
    - Упрощённая отладка получения данных с агентов
    - Простота настройки и управления — система мониторинга активно забирает метрики из заданных источников с регулярными интервалами.
    - Интеграция с механизмами обнаружения сервисов (например, Kubernetes, Consul) — система автоматически обнаруживает и собирает метрики из новых источников по мере их появления.
#
    Минусы:
    - Проблемы с масштабируемостью — по мере увеличения количества источников требуется больше ресурсов для управления.
    - Сложность управления конфигурационными файлами для обнаружения источников и правил сбора метрик, особенно в крупномасштабных развертываниях.
    - Потребление ресурсов — частое сбор метрик может увеличить нагрузку на контролируемые сервисы и сервер мониторинга, потенциально влияя на производительность.
    - Потенциальное время простоя — если система мониторинга падает или возникают проблемы с сетью, может быть задержка в сборе метрик до следующего запланированного сбора.
#
6. Какие из ниже перечисленных систем относятся к push модели, а какие к pull? А может есть гибридные?

    - Prometheus - тип PULL 
    - TICK - тип PUSH
    - Zabbix - гибридная система мониторинга
    - VictoriaMetrics - гибридная система мониторинга
    - Nagios - тип PULL
#
7. Склонируйте себе [репозиторий](https://github.com/influxdata/sandbox/tree/master) и запустите TICK-стэк, 
используя технологии docker и docker-compose.

В виде решения на это упражнение приведите скриншот веб-интерфейса ПО chronograf (`http://localhost:8888`). 

P.S.: если при запуске некоторые контейнеры будут падать с ошибкой - проставьте им режим `Z`, например
`./data:/var/lib:Z`
#
8. Перейдите в веб-интерфейс Chronograf (http://localhost:8888) и откройте вкладку Data explorer.
        
    - Нажмите на кнопку Add a query
    - Изучите вывод интерфейса и выберите БД telegraf.autogen
    - В `measurments` выберите cpu->host->telegraf-getting-started, а в `fields` выберите usage_system. Внизу появится график утилизации cpu.
    - Вверху вы можете увидеть запрос, аналогичный SQL-синтаксису. Поэкспериментируйте с запросом, попробуйте изменить группировку и интервал наблюдений.

Для выполнения задания приведите скриншот с отображением метрик утилизации cpu из веб-интерфейса.
#
9. Изучите список [telegraf inputs](https://github.com/influxdata/telegraf/tree/master/plugins/inputs). 
Добавьте в конфигурацию telegraf следующий плагин - [docker](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/docker):
```
[[inputs.docker]]
  endpoint = "unix:///var/run/docker.sock"
```

Дополнительно вам может потребоваться донастройка контейнера telegraf в `docker-compose.yml` дополнительного volume и 
режима privileged:
```
  telegraf:
    image: telegraf:1.4.0
    privileged: true
    volumes:
      - ./etc/telegraf.conf:/etc/telegraf/telegraf.conf:Z
      - /var/run/docker.sock:/var/run/docker.sock:Z
    links:
      - influxdb
    ports:
      - "8092:8092/udp"
      - "8094:8094"
      - "8125:8125/udp"
```

После настройке перезапустите telegraf, обновите веб интерфейс и приведите скриншотом список `measurments` в 
веб-интерфейсе базы telegraf.autogen . Там должны появиться метрики, связанные с docker.

Факультативно можете изучить какие метрики собирает telegraf после выполнения данного задания.